{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß† EEG-to-Text Seq2Seq Training (BEST APPROACH)\n",
        "\n",
        "## üìã Overview\n",
        "- **Model**: Sequence-to-Sequence LSTM with Attention\n",
        "- **Approach**: Generates sentences word-by-word (like machine translation)\n",
        "- **Expected Results**: MUCH BETTER than classification\n",
        "- **Training Time**: 3-5 hours on CPU\n",
        "\n",
        "## ‚úÖ Why Seq2Seq is Better\n",
        "1. **Partial credit**: Gets credit for predicting some words correctly\n",
        "2. **Works with 95 classes**: Can learn from limited data per class\n",
        "3. **More realistic**: Like translating EEG ‚Üí English text\n",
        "4. **Better metrics**: Word Error Rate (WER), not just exact match\n",
        "5. **Flexible**: Can potentially generate new sentences\n",
        "\n",
        "## üéØ Expected Results (95 classes)\n",
        "- **Word Error Rate (WER)**: 40-60% (lower is better)\n",
        "- **Exact Match Accuracy**: 10-20% (higher than classification)\n",
        "- **Partial correctness**: Gets 60-80% of words right even if sentence is wrong\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"\\n‚úÖ Google Drive mounted successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Clone Repository from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Clone repository (or pull latest changes if already exists)\n",
        "if not os.path.exists('/content/ML-Project-Data'):\n",
        "    print(\"üì• Cloning repository from GitHub...\")\n",
        "    !git clone https://github.com/Tejas-Chakkarwar/ML-Project-Data.git\n",
        "    print(\"‚úÖ Repository cloned!\")\n",
        "else:\n",
        "    print(\"‚úÖ Repository already exists\")\n",
        "    print(\"üì• Pulling latest changes...\")\n",
        "    !cd /content/ML-Project-Data && git pull origin main\n",
        "\n",
        "# Change to project directory\n",
        "os.chdir('/content/ML-Project-Data')\n",
        "print(f\"\\n‚úÖ Working directory: {os.getcwd()}\")\n",
        "\n",
        "# Verify Seq2Seq files\n",
        "print(\"\\nüìã Verifying Seq2Seq files:\")\n",
        "print(f\"  lstm_approach/: {'‚úÖ' if os.path.exists('lstm_approach') else '‚ùå MISSING'}\")\n",
        "print(f\"  lstm_approach/train_seq2seq.py: {'‚úÖ' if os.path.exists('lstm_approach/train_seq2seq.py') else '‚ùå MISSING'}\")\n",
        "print(f\"  lstm_approach/seq2seq_model.py: {'‚úÖ' if os.path.exists('lstm_approach/seq2seq_model.py') else '‚ùå MISSING'}\")\n",
        "print(f\"  lstm_approach/vocabulary.py: {'‚úÖ' if os.path.exists('lstm_approach/vocabulary.py') else '‚ùå MISSING'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q torch numpy pandas scikit-learn tqdm\n",
        "\n",
        "# Check GPU availability\n",
        "import torch\n",
        "\n",
        "print(\"\\nüìä System Information:\")\n",
        "print(f\"  GPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"  GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(\"\\n  ‚úÖ GPU enabled - Training will be much faster!\")\n",
        "    DEVICE = 'cuda'\n",
        "else:\n",
        "    print(\"\\n  ‚ö†Ô∏è No GPU detected - using CPU\")\n",
        "    print(\"  Training will take 3-5 hours\")\n",
        "    DEVICE = 'cpu'\n",
        "\n",
        "print(\"\\n‚úÖ Dependencies installed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Copy Dataset from Google Drive\n",
        "\n",
        "‚ö†Ô∏è **IMPORTANT**: Update the `SOURCE` path below to match your dataset location!\n",
        "\n",
        "Common paths:\n",
        "- `/content/drive/MyDrive/ML_Project_Dataset`\n",
        "- `/content/drive/MyDrive/Colab Notebooks/dataset`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import shutil\n",
        "import os\n",
        "import glob\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"COPYING DATASET FROM GOOGLE DRIVE\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# ‚ö†Ô∏è UPDATE THIS PATH TO YOUR ACTUAL DATASET LOCATION!\n",
        "SOURCE = '/content/drive/MyDrive/ML_Project_Dataset'  # ‚Üê Change this!\n",
        "DEST = '/content/ML-Project-Data/processed_data'\n",
        "\n",
        "# Verify source exists\n",
        "if not os.path.exists(SOURCE):\n",
        "    print(f\"\\n‚ùå ERROR: Source path not found!\")\n",
        "    print(f\"   Path: {SOURCE}\")\n",
        "    print(\"\\nüìÅ Available folders in MyDrive:\")\n",
        "    for item in os.listdir('/content/drive/MyDrive'):\n",
        "        item_path = os.path.join('/content/drive/MyDrive', item)\n",
        "        if os.path.isdir(item_path):\n",
        "            print(f\"   üìÅ {item}/\")\n",
        "    print(\"\\n‚ö†Ô∏è Please update the SOURCE path in the cell above!\")\n",
        "else:\n",
        "    # Create destination\n",
        "    os.makedirs(DEST, exist_ok=True)\n",
        "    \n",
        "    # Get list of files\n",
        "    all_files = sorted(os.listdir(SOURCE))\n",
        "    total_files = len(all_files)\n",
        "    \n",
        "    print(f\"\\n‚úÖ Source found: {SOURCE}\")\n",
        "    print(f\"üìä Total files to copy: {total_files:,}\")\n",
        "    \n",
        "    # Check what's already copied\n",
        "    already_copied = set(os.listdir(DEST)) if os.path.exists(DEST) else set()\n",
        "    print(f\"üìä Already copied: {len(already_copied):,}\")\n",
        "    print(f\"üìä Remaining: {total_files - len(already_copied):,}\\n\")\n",
        "    \n",
        "    # Copy files with progress\n",
        "    copied = 0\n",
        "    failed = []\n",
        "    start_time = time.time()\n",
        "    \n",
        "    for i, filename in enumerate(all_files, 1):\n",
        "        if filename in already_copied:\n",
        "            continue\n",
        "        \n",
        "        src_path = os.path.join(SOURCE, filename)\n",
        "        dst_path = os.path.join(DEST, filename)\n",
        "        \n",
        "        try:\n",
        "            if os.path.isfile(src_path):\n",
        "                shutil.copy2(src_path, dst_path)\n",
        "                copied += 1\n",
        "        except Exception as e:\n",
        "            failed.append(filename)\n",
        "        \n",
        "        if (i % 1000 == 0) or (i == total_files):\n",
        "            elapsed = time.time() - start_time\n",
        "            print(f\"   [{i:,}/{total_files:,}] Progress ({elapsed/60:.1f} min)\")\n",
        "    \n",
        "    elapsed = time.time() - start_time\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"COPY COMPLETE\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"‚è±Ô∏è  Time: {elapsed/60:.1f} minutes\")\n",
        "    print(f\"‚úÖ Copied: {copied:,} files\")\n",
        "    print(f\"üìä Already existed: {len(already_copied):,} files\")\n",
        "    print(f\"‚ùå Failed: {len(failed)} files\")\n",
        "    \n",
        "    # Verify\n",
        "    csv_files = glob.glob(f'{DEST}/rawdata_*.csv')\n",
        "    mapping_exists = os.path.exists(f'{DEST}/sentence_mapping.csv')\n",
        "    \n",
        "    print(f\"\\nüìã Final Verification:\")\n",
        "    print(f\"   CSV files: {len(csv_files):,}\")\n",
        "    print(f\"   Mapping file: {'‚úÖ' if mapping_exists else '‚ùå'}\")\n",
        "    \n",
        "    if len(csv_files) >= 5900 and mapping_exists:\n",
        "        print(\"\\nüéâ SUCCESS! Data is ready for training!\")\n",
        "    else:\n",
        "        print(f\"\\n‚ö†Ô∏è  Warning: Only {len(csv_files):,} files (expected ~5,915)\")\n",
        "    \n",
        "    print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Train Seq2Seq Model (95 Classes)\n",
        "\n",
        "### üéØ Configuration:\n",
        "- **Classes**: ~95 (min_samples=18)\n",
        "- **Approach**: Generate sentences word-by-word\n",
        "- **Vocabulary**: Built from all training sentences\n",
        "- **Augmentation**: 6x (more training data)\n",
        "\n",
        "### ‚è±Ô∏è Expected:\n",
        "- **Training time**: 3-5 hours on CPU / 1-2 hours on GPU\n",
        "- **Word Error Rate**: 40-60% (lower is better)\n",
        "- **Exact Match**: 10-20% (better than classification's 4-7%)\n",
        "- **Partial correctness**: 60-80% of words correct\n",
        "\n",
        "---\n",
        "\n",
        "**‚ö†Ô∏è This cell will take 3-5 hours to complete. Don't close your browser!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "os.chdir('/content/ML-Project-Data/lstm_approach')\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üöÄ SEQ2SEQ EEG-TO-TEXT TRAINING\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nüéØ Configuration:\")\n",
        "print(\"  ‚úÖ Classes: ~95 (min_samples=18)\")\n",
        "print(\"  ‚úÖ Approach: Word-by-word generation\")\n",
        "print(\"  ‚úÖ Augmentation: 6x\")\n",
        "print(\"  ‚úÖ Model: Encoder-Decoder LSTM with Attention\")\n",
        "print(f\"  ‚úÖ Device: {DEVICE}\")\n",
        "print()\n",
        "print(\"üíæ Expected Memory: ~6-8 GB RAM\")\n",
        "print(\"‚è±Ô∏è  Expected Time: 3-5 hours (CPU) / 1-2 hours (GPU)\")\n",
        "print(\"üéØ Target WER: 40-60%\")\n",
        "print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "!python train_seq2seq.py \\\n",
        "  --min-samples 18 \\\n",
        "  --num-aug 6 \\\n",
        "  --batch-size 16 \\\n",
        "  --epochs 40 \\\n",
        "  --lr 0.001 \\\n",
        "  --teacher-forcing 0.5 \\\n",
        "  --device {DEVICE} \\\n",
        "  --max-len 60\n",
        "\n",
        "elapsed = time.time() - start\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(f\"üéâ TRAINING COMPLETED IN {elapsed/60:.1f} MINUTES ({elapsed/3600:.1f} HOURS)\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Save Models to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Create destination in Google Drive\n",
        "DRIVE_MODELS_DIR = '/content/drive/MyDrive/ML_Project_Seq2Seq_Models'\n",
        "os.makedirs(DRIVE_MODELS_DIR, exist_ok=True)\n",
        "\n",
        "# Copy checkpoints\n",
        "LOCAL_CHECKPOINT_DIR = '/content/ML-Project-Data/checkpoints'\n",
        "\n",
        "if os.path.exists(LOCAL_CHECKPOINT_DIR):\n",
        "    print(\"üì¶ Saving Seq2Seq model to Google Drive...\\n\")\n",
        "    \n",
        "    for filename in os.listdir(LOCAL_CHECKPOINT_DIR):\n",
        "        if filename.endswith('.pth'):\n",
        "            src = os.path.join(LOCAL_CHECKPOINT_DIR, filename)\n",
        "            dst = os.path.join(DRIVE_MODELS_DIR, filename)\n",
        "            \n",
        "            shutil.copy2(src, dst)\n",
        "            size_mb = os.path.getsize(dst) / 1e6\n",
        "            print(f\"‚úÖ {filename} ({size_mb:.1f} MB)\")\n",
        "    \n",
        "    print(f\"\\n‚úÖ Models saved to: {DRIVE_MODELS_DIR}\")\n",
        "    print(\"   These will persist even after session ends!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No checkpoints found. Did training complete successfully?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7 (Optional): Quick Test on 5 Classes\n",
        "\n",
        "If you want faster results for demonstration, train on 5 most common sentences.\n",
        "Expected: **60-80% exact match**, **20-30% WER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "os.chdir('/content/ML-Project-Data/lstm_approach')\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üöÄ SEQ2SEQ TRAINING - 5 CLASSES (DEMO)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "!python train_seq2seq.py \\\n",
        "  --min-samples 20 \\\n",
        "  --num-aug 6 \\\n",
        "  --batch-size 16 \\\n",
        "  --epochs 30 \\\n",
        "  --lr 0.001 \\\n",
        "  --teacher-forcing 0.5 \\\n",
        "  --device {DEVICE} \\\n",
        "  --max-len 40\n",
        "\n",
        "elapsed = time.time() - start\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(f\"üéâ TRAINING COMPLETED IN {elapsed/60:.1f} MINUTES\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìä Understanding Your Results\n",
        "\n",
        "### Metrics Explained:\n",
        "\n",
        "1. **Exact Match Accuracy**: Percentage of sentences predicted perfectly\n",
        "   - 95 classes: 10-20% is GOOD (much better than 4-7% classification)\n",
        "   - 5 classes: 60-80% is EXCELLENT\n",
        "\n",
        "2. **Word Error Rate (WER)**: Percentage of words that are wrong\n",
        "   - Lower is better\n",
        "   - 40-60% means 40-60% of words are wrong (or 40-60% correct)\n",
        "   - This shows partial understanding\n",
        "\n",
        "### Why Seq2Seq is Better:\n",
        "- Classification: **All or nothing** (entire sentence must be correct)\n",
        "- Seq2Seq: **Partial credit** (gets points for correct words)\n",
        "\n",
        "### Example:\n",
        "```\n",
        "True: \"The cat sat on the mat\"\n",
        "Pred: \"The dog sat on the chair\"\n",
        "\n",
        "Classification: 0% (wrong sentence)\n",
        "Seq2Seq: 66% (4/6 words correct, WER = 33%)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ For Your Presentation\n",
        "\n",
        "**Recommended approach:**\n",
        "1. Show 5-class results (60-80% exact match)\n",
        "2. Explain Seq2Seq generates word-by-word\n",
        "3. Show examples of partial correctness\n",
        "4. Compare with classification (4-7% for 95 classes)\n",
        "5. Mention 95-class WER shows model understands patterns\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
